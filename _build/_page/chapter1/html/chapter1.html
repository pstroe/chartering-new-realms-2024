
<!DOCTYPE html>


<html lang="en" data-content_root="./" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Chapter 1: From Data to Corpus &#8212; Chartering New Realms; AI as a Catalyst in Digital Humanities</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  <!-- 
    this give us a css class that will be invisible only if js is disabled 
  -->
  <noscript>
    <style>
      .pst-js-only { display: none !important; }

    </style>
  </noscript>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=26a4bc78f4c0ddb94549" rel="stylesheet" />
<link href="_static/styles/pydata-sphinx-theme.css?digest=26a4bc78f4c0ddb94549" rel="stylesheet" />

    <link rel="stylesheet" type="text/css" href="_static/pygments.css?v=fa44fd50" />
    <link rel="stylesheet" type="text/css" href="_static/styles/sphinx-book-theme.css?v=a3416100" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css?v=be8a1c11" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-design.min.css?v=95c83b7e" />
  
  <!-- So that users can add custom icons -->
  <script src="_static/scripts/fontawesome.js?digest=26a4bc78f4c0ddb94549"></script>
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/bootstrap.js?digest=26a4bc78f4c0ddb94549" />
<link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=26a4bc78f4c0ddb94549" />

    <script src="_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="_static/doctools.js?v=9a2dae69"></script>
    <script src="_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="_static/copybutton.js?v=f281be69"></script>
    <script src="_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="_static/design-tabs.js?v=f930bc37"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'chapter1';</script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  <meta name="docsearch:version" content="" />
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <dialog id="pst-search-dialog">
    
<form class="bd-search d-flex align-items-center"
      action="search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
  </dialog>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
        
      
      <dialog id="pst-primary-sidebar-modal"></dialog>
      <div id="pst-primary-sidebar" class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="#">
  
  
  
  
  
    
    
      
    
    
    <img src="_static/chartering-new-realms-logo.png" class="logo__image only-light" alt="Chartering New Realms; AI as a Catalyst in Digital Humanities - Home"/>
    <img src="_static/chartering-new-realms-logo.png" class="logo__image only-dark pst-js-only" alt="Chartering New Realms; AI as a Catalyst in Digital Humanities - Home"/>
  
  
</a></div>
        <div class="sidebar-primary-item">

<button class="btn search-button-field search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
 <i class="fa-solid fa-magnifying-glass"></i>
 <span class="search-button__default-text">Search</span>
 <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
</button></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1 current active">
                <a class="reference internal" href="#">
                    Chapter 1: From Data to Corpus
                </a>
            </li>
        </ul>
        
    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-launch-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Launch interactive content">
    <i class="fas fa-rocket"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li>
<button onclick="initThebeSBT()"
  class="btn btn-sm btn-launch-thebe dropdown-item"
  title="Launch Thebe"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-play"></i>
  </span>
<span class="btn__text-container">Live Code</span>
</button>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/executablebooks/jupyter-book" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/executablebooks/jupyter-book/issues/new?title=Issue%20on%20page%20%2Fchapter1.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="_sources/chapter1.ipynb" target="_blank"
   class="btn btn-sm btn-download-notebook-button dropdown-item"
   title="Download notebook file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-code"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li><a href="_sources/chapter1.md" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.md</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button pst-js-only" aria-label="Color mode" data-bs-title="Color mode"  data-bs-placement="bottom" data-bs-toggle="tooltip">
  <i class="theme-switch fa-solid fa-sun                fa-lg" data-mode="light" title="Light"></i>
  <i class="theme-switch fa-solid fa-moon               fa-lg" data-mode="dark"  title="Dark"></i>
  <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"  title="System Settings"></i>
</button>


<button class="btn btn-sm pst-navbar-icon search-button search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
</button>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Chapter 1: From Data to Corpus</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#abstract">Abstract</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#introduction">Introduction</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#relevant-literature">Relevant Literature</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#data-and-methods">Data and Methods</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#data">Data</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#parlamint">ParlaMint</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#pre-processing">Pre-Processing</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#method">Method</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#experiment-setup">Experiment Setup</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#experiments-and-results">Experiments and Results</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#results-discussion">Results &amp; Discussion</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#limitations">Limitations</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#conclusion">Conclusion</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#bibliography">Bibliography</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section id="chapter-1-from-data-to-corpus">
<h1>Chapter 1: From Data to Corpus<a class="headerlink" href="#chapter-1-from-data-to-corpus" title="Link to this heading">#</a></h1>
<p>Anouk Menzi, Elizabeth Wagner</p>
<section id="abstract">
<h2>Abstract<a class="headerlink" href="#abstract" title="Link to this heading">#</a></h2>
<p>#We will write this in the end</p>
</section>
<section id="introduction">
<h2>Introduction<a class="headerlink" href="#introduction" title="Link to this heading">#</a></h2>
<p>Scholars spend many hours on preprocessing raw data into structured collections that suit their needs <span id="id1">[<a class="reference internal" href="#id67" title="Zui Chen, Lei Cao, and Sam et al. Madden. SEED: Domain-Specific Data Curation With Large Language Models. 2023. Version Number: 3. URL: https://arxiv.org/abs/2310.00749 (visited on 2024-10-16), doi:10.48550/ARXIV.2310.00749.">Chen <em>et al.</em>, 2023</a>]</span>. This process is time and resource intensive, especially when dealing with natural language. Considering the current trend in the digital humanities away from big data towards massive data, the questions of making data Findable, Accessible, Interoperable, and Reusable <span id="id2">[<a class="reference internal" href="#id62" title="Mark D. Wilkinson, Michel Dumontier, and IJsbrand Jan Aalbersberg. The FAIR Guiding Principles for scientific data management and stewardship. Scientific Data, 3:1–9, March 2016. URL: https://doi.org/10.1038/sdata.2016.18, doi:10.1038/sdata.2016.18.">Wilkinson <em>et al.</em>, 2016</a>]</span> have become a focus area of constructing data collections <span id="id3">[<a class="reference internal" href="#id61" title="Nancy Ide, Laurent Romary, and Eric de la Clergerie. International standard for a linguistic annotation framework. In Proceedings of the HLT-NAACL 2003 Workshop on Software Engineering and Architecture of Language Technology Systems - Volume 8, SEALTS '03, 25-–30. USA, 2003. Association for Computational Linguistics. URL: https://doi.org/10.3115/1119226.1119230, doi:10.3115/1119226.1119230.">Ide <em>et al.</em>, 2003</a>, <a class="reference internal" href="#id55" title="Alexander König, Jennifer-Carmen Frey, and Egon W. Stemle. Exploring Reusability and Reproducibility for a Research Infrastructure for L1 and L2 Learner Corpora. Information, 12(5):199, April 2021. URL: https://www.mdpi.com/2078-2489/12/5/199 (visited on 2024-10-30), doi:10.3390/info12050199.">König <em>et al.</em>, 2021</a>]</span>. An attempt at making data accessible, interoprable, and reusable can be found in the Text Encoding Initiative <span id="id4">[<a class="reference internal" href="#id81" title="Lou Burnard. The Evolution of the Text Encoding Initiative: From Research Project to Research Infrastructure. Journal of the Text Encoding Initiative, April 2013. URL: http://journals.openedition.org/jtei/811 (visited on 2024-11-28), doi:10.4000/jtei.811.">Burnard, 2013</a>]</span>. In this chapter, we propose an approach to the construction of structured data collections with the assistance of Large Language Models, LLMs, to reduce the amount of human labour invested in preprocessing using the ParliMINT scheme, an interoperable TEI xml scheme for transcripts of parliamentary proceedings. This approach serves especially well in cases where there is much raw data but which has not been structured into data collections, as is the case for the variations of South African English <span id="id5">[<a class="reference internal" href="#id58" title="Chris Jeffery. On compiling a corpus of South African English. Southern African Linguistics and Applied Language Studies, 21(4):341–344, November 2003. URL: http://www.tandfonline.com/doi/abs/10.2989/16073610309486353 (visited on 2024-10-05), doi:10.2989/16073610309486353.">Jeffery, 2003</a>, <a class="reference internal" href="#id56" title="Leela Pienaar and Vivian De Klerk. Towards a Corpus of South African English: Corralling the Sub-varieties. Lexikos, October 2011. URL: http://lexikos.journals.ac.za/pub/article/view/444 (visited on 2024-10-05), doi:10.5788/19-0-444.">Pienaar and De Klerk, 2011</a>]</span>. One such source of raw data constitutes the South African parliamentary proceedings. The South African Parliament supplies transcripts of its parliamentary proceedings online, and whilst attempts have been made to format this data into the ParliMINT scheme, the attempt has been labour intensive and done only on a small scale <span id="id6">[<a class="reference internal" href="#id60" title="Maciej Ogrodniczuk. Towards Including South African Hansard Papers in the ParlaMint schema. Journal of the Digital Humanities Association of Southern Africa (DHASA), February 2024. URL: https://upjournals.up.ac.za/index.php/dhasa/article/view/5025 (visited on 2024-09-23).">Ogrodniczuk, 2024</a>]</span>. This chapter thus shall attempt to format the parliamentary proceedings into an interoperable XML scheme with the aid of different LLMs without the use of industrial strength hardware.</p>
</section>
<section id="relevant-literature">
<h2>Relevant Literature<a class="headerlink" href="#relevant-literature" title="Link to this heading">#</a></h2>
<blockquote>
<div><p>Parliamentary proceedings (PP) are a rich source of data used by e.g. scholars in historiography, sociology, political science, linguistics, economics and economic history. As opposed to sources of most other language corpora, PP are not subject to copyright or personal privacy protections, and are typically available online thus making them ideal for compilation into corpora and open distribution. For these reasons many countries have already produced PP corpora, but each typically in their own encoding, thus limiting their comparability and utilisation in a multilingual setting <span id="id7">[<a class="reference internal" href="#id79">Erjavec and Pančur, 2019</a>]</span>.</p>
</div></blockquote>
<p>ParlaMint was suggested as interoperable, adaptive framework of formatting non-standardised parliamentary proceedings <span id="id8">[<a class="reference internal" href="#id80" title="Tomaž Erjavec, Maciej Ogrodniczuk, Petya Osenova, Nikola Ljubešić, Kiril Simov, Andrej Pančur, Michał Rudolf, Matyáš Kopp, Starkaður Barkarson, Steinþór Steingrímsson, Çağrı Çöltekin, Jesse De Does, Katrien Depuydt, Tommaso Agnoloni, Giulia Venturi, María Calzada Pérez, Luciana D. De Macedo, Costanza Navarretta, Giancarlo Luxardo, Matthew Coole, Paul Rayson, Vaidas Morkevičius, Tomas Krilavičius, Roberts Darǵis, Orsolya Ring, Ruben Van Heusden, Maarten Marx, and Darja Fišer. The ParlaMint corpora of parliamentary proceedings. Language Resources and Evaluation, 57(1):415–448, March 2023. URL: https://link.springer.com/10.1007/s10579-021-09574-0 (visited on 2024-10-01), doi:10.1007/s10579-021-09574-0.">Erjavec <em>et al.</em>, 2023</a>]</span>. A first attempt at including the South African Parliamentary Proceedings has been made by Ogrodniczuk <span id="id9">Ogrodniczuk [<a class="reference internal" href="#id60" title="Maciej Ogrodniczuk. Towards Including South African Hansard Papers in the ParlaMint schema. Journal of the Digital Humanities Association of Southern Africa (DHASA), February 2024. URL: https://upjournals.up.ac.za/index.php/dhasa/article/view/5025 (visited on 2024-09-23).">2024</a>]</span>, highlighting again the difficulties of formatting an unstructed document into the ParlaMint scheme <span id="id10">[<a class="reference internal" href="#id80" title="Tomaž Erjavec, Maciej Ogrodniczuk, Petya Osenova, Nikola Ljubešić, Kiril Simov, Andrej Pančur, Michał Rudolf, Matyáš Kopp, Starkaður Barkarson, Steinþór Steingrímsson, Çağrı Çöltekin, Jesse De Does, Katrien Depuydt, Tommaso Agnoloni, Giulia Venturi, María Calzada Pérez, Luciana D. De Macedo, Costanza Navarretta, Giancarlo Luxardo, Matthew Coole, Paul Rayson, Vaidas Morkevičius, Tomas Krilavičius, Roberts Darǵis, Orsolya Ring, Ruben Van Heusden, Maarten Marx, and Darja Fišer. The ParlaMint corpora of parliamentary proceedings. Language Resources and Evaluation, 57(1):415–448, March 2023. URL: https://link.springer.com/10.1007/s10579-021-09574-0 (visited on 2024-10-01), doi:10.1007/s10579-021-09574-0.">Erjavec <em>et al.</em>, 2023</a>]</span>. The experiment was conducted on a singular session with a rule based approach <span id="id11">[<a class="reference internal" href="#id60" title="Maciej Ogrodniczuk. Towards Including South African Hansard Papers in the ParlaMint schema. Journal of the Digital Humanities Association of Southern Africa (DHASA), February 2024. URL: https://upjournals.up.ac.za/index.php/dhasa/article/view/5025 (visited on 2024-09-23).">Ogrodniczuk, 2024</a>]</span>. This proved difficult as all quotations had to be marked manually, thus making it a labour intensive process when considering the 25 years of proceedings available for download on <a class="reference external" href="https://www.parliament.gov.za/hansard">the website of the South African Parliament</a> <span id="id12">[<a class="reference internal" href="#id60" title="Maciej Ogrodniczuk. Towards Including South African Hansard Papers in the ParlaMint schema. Journal of the Digital Humanities Association of Southern Africa (DHASA), February 2024. URL: https://upjournals.up.ac.za/index.php/dhasa/article/view/5025 (visited on 2024-09-23).">Ogrodniczuk, 2024</a>, <a class="reference internal" href="#id78" title="Naomi Truan and Laurent Romary. Building, Encoding, and Annotating a Corpus of Parliamentary Debates in TEI XML: A Cross-Linguistic Account. Journal of the Text Encoding Initiative, March 2021. URL: http://journals.openedition.org/jtei/4164 (visited on 2024-09-27), doi:10.4000/jtei.4164.">Truan and Romary, 2021</a>]</span>.</p>
<p>The primary attractivity of harnessing LLMs lies in their capability to process Natural Language inputs and their generalized applicability to unknown tasks <span id="id13">[<a class="reference internal" href="#id69" title="Avanika Narayan, Ines Chami, Laurel Orr, and Christopher Ré. Can Foundation Models Wrangle Your Data? Proceedings of the VLDB Endowment, 16(4):738–746, December 2022. URL: https://dl.acm.org/doi/10.14778/3574245.3574258 (visited on 2024-10-16), doi:10.14778/3574245.3574258.">Narayan <em>et al.</em>, 2022</a>, <a class="reference internal" href="#id74" title="Haochen Zhang, Yuyang Dong, and Chuan et al. Xiao. Jellyfish: Instruction-Tuning Local Large Language Models for Data Preprocessing. In Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing, 8754–8782. Association for Computational Linguistics, November 2024.">Zhang <em>et al.</em>, 2024</a>]</span>. In this they are more flexible than specialized tools. Their flexibility is especially appreciated when it comes to the robustness of processing as, because they are not rule based, they are able to adapt to unforseen circumstances <span id="id14">[<a class="reference internal" href="#id74" title="Haochen Zhang, Yuyang Dong, and Chuan et al. Xiao. Jellyfish: Instruction-Tuning Local Large Language Models for Data Preprocessing. In Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing, 8754–8782. Association for Computational Linguistics, November 2024.">Zhang <em>et al.</em>, 2024</a>]</span>. In this ability they have found a wide application ground within the field of linguistics such as in Zappavigna where ChatGPT was tasked with evaluating noisy social media data <span id="id15">[<a class="reference internal" href="#id57" title="Michele Zappavigna. Hack your corpus analysis: How AI can assist corpus linguists deal with messy social media data. Applied Corpus Linguistics, 3(3):100067, December 2023. URL: https://linkinghub.elsevier.com/retrieve/pii/S2666799123000278 (visited on 2024-10-01), doi:10.1016/j.acorp.2023.100067.">Zappavigna, 2023</a>]</span> or in the use of generative LLMs for corpus analysis <span id="id16">[<a class="reference internal" href="#id59" title="Niall Curry, Paul Baker, and Gavin Brookes. Generative AI for corpus approaches to discourse studies: A critical evaluation of ChatGPT. Applied Corpus Linguistics, 4(1):100082, April 2024. URL: https://linkinghub.elsevier.com/retrieve/pii/S2666799123000424 (visited on 2024-09-27).">Curry <em>et al.</em>, 2024</a>]</span>. As to the knowledge of the authors of this chapter, no attempts at harnessing LLMs for parliamentary corpus building specifically have been attempted. However, in the wider field of data curation and formatting, the capabilities of LLMs are utilized, for example in summarising healthcare data from semi-structured forms into possible schematas of illnesses <span id="id17">[<a class="reference internal" href="#id71" title="Louis Létinier, Julien Jouganous, and Mehdi et al. Benkebil. Artificial Intelligence for Unstructured Healthcare Data: Application to Coding of Patient Reporting of Adverse Drug Reactions. Clinical Pharmacology &amp; Therapeutics, 110(2):392–400, August 2021. URL: https://ascpt.onlinelibrary.wiley.com/doi/10.1002/cpt.2266 (visited on 2024-10-04), doi:10.1002/cpt.2266.">Létinier <em>et al.</em>, 2021</a>]</span> or in processing natural language for the biomedical field into a reusable format <span id="id18">[<a class="reference internal" href="#id70" title="Tim Beck, Tom Shorter, and Yan et al. Hu. Auto-CORPus: A Natural Language Processing Tool for Standardizing and Reusing Biomedical Literature. Frontiers in Digital Health, 4:788124, February 2022. URL: https://www.frontiersin.org/articles/10.3389/fdgth.2022.788124/full (visited on 2024-10-09), doi:10.3389/fdgth.2022.788124.">Beck <em>et al.</em>, 2022</a>]</span>. These adaptations of LLMs are highly specialized for their respective tasks and have thus lost much of their generality which is so desired by data scientists in their quest for a one-stop-shop solution for data wrangling <span id="id19">[]</span>. A further issue of these specialized tasks lie in the idea that LLMs also mark faulty data, respectively correct these errors, such as in customer databases <span id="id20">[<a class="reference internal" href="#id72" title="Jaseem Pookandy. AI-Based Data Cleaning and Management in Salesforce CRM for Improving Data Integrity and Accuracy to Enhance Customer Insights. International Journal of Advanced Research in Engineering and Technology, 13(5):108–116, May 2022. URL: https://iaeme.com/Home/issue/IJARET?Volume=13&amp;Issue=5.">Pookandy, 2022</a>]</span>. A behaviour which, in the field of linguistics, is at its best irrelevant but rather more likely renders the data worthless as it would alter the transcripts.</p>
<p>In light of these added difficulties when it comes to language data where the language itself is of importance, research has largely been based on developping a tool that in its foundations is based on LLMs but that also includes rule based code to wrangle data <span id="id21">[<a class="reference internal" href="#id68" title="Simran Arora, Brandon Yang, and Sabri et al. Eyuboglu. Language Models Enable Simple Systems for Generating Structured Views of Heterogeneous Data Lakes. Proceedings of the VLDB Endowment, 17(2):92–105, October 2023. URL: https://dl.acm.org/doi/10.14778/3626292.3626294 (visited on 2024-10-16), doi:10.14778/3626292.3626294.">Arora <em>et al.</em>, 2023</a>, <a class="reference internal" href="#id67" title="Zui Chen, Lei Cao, and Sam et al. Madden. SEED: Domain-Specific Data Curation With Large Language Models. 2023. Version Number: 3. URL: https://arxiv.org/abs/2310.00749 (visited on 2024-10-16), doi:10.48550/ARXIV.2310.00749.">Chen <em>et al.</em>, 2023</a>]</span>. Evaporate is capable of transforming various, semistructured inputs into a table output, however it’s LLM components are based on using cloud solutions to run LLMs <span id="id22">[<a class="reference internal" href="#id68" title="Simran Arora, Brandon Yang, and Sabri et al. Eyuboglu. Language Models Enable Simple Systems for Generating Structured Views of Heterogeneous Data Lakes. Proceedings of the VLDB Endowment, 17(2):92–105, October 2023. URL: https://dl.acm.org/doi/10.14778/3626292.3626294 (visited on 2024-10-16), doi:10.14778/3626292.3626294.">Arora <em>et al.</em>, 2023</a>]</span>. SEED works on a similar basis, though it’s output format can be customised <a class="footnote-reference brackets" href="#footnote1" id="id23" role="doc-noteref"><span class="fn-bracket">[</span>1<span class="fn-bracket">]</span></a>. A model specifically fine-tuned for dataprocessing is the jellyfish family as proposed by Zhang et al. which is based on the smaller models of the Llama 3 family <span id="id24">Zhang <em>et al.</em> [<a class="reference internal" href="#id74" title="Haochen Zhang, Yuyang Dong, and Chuan et al. Xiao. Jellyfish: Instruction-Tuning Local Large Language Models for Data Preprocessing. In Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing, 8754–8782. Association for Computational Linguistics, November 2024.">2024</a>]</span>. These tools display a remarkable adaptivity to new tasks, especially when employing a technique called few-shot prompting, where a model, or tool, is supplied with several examples before it is set to the task <span id="id25">[<a class="reference internal" href="#id67" title="Zui Chen, Lei Cao, and Sam et al. Madden. SEED: Domain-Specific Data Curation With Large Language Models. 2023. Version Number: 3. URL: https://arxiv.org/abs/2310.00749 (visited on 2024-10-16), doi:10.48550/ARXIV.2310.00749.">Chen <em>et al.</em>, 2023</a>]</span>. However, this comes at a greater computational cost than when employing non-LLM tools or rule-based tools <span id="id26">[<a class="reference internal" href="#id68" title="Simran Arora, Brandon Yang, and Sabri et al. Eyuboglu. Language Models Enable Simple Systems for Generating Structured Views of Heterogeneous Data Lakes. Proceedings of the VLDB Endowment, 17(2):92–105, October 2023. URL: https://dl.acm.org/doi/10.14778/3626292.3626294 (visited on 2024-10-16), doi:10.14778/3626292.3626294.">Arora <em>et al.</em>, 2023</a>]</span>. In this the trade-off between robustness and human-costliness, and energy efficience must be a carefully calculated balance.</p>
</section>
<section id="data-and-methods">
<h2>Data and Methods<a class="headerlink" href="#data-and-methods" title="Link to this heading">#</a></h2>
<section id="data">
<h3>Data<a class="headerlink" href="#data" title="Link to this heading">#</a></h3>
<p>The data was extracted from the official website for the Hansard of the Parliament of the Republic of South Africa. It constitutes the transcripts of the mini plenary sessions of the National Assembly, the National Council of Provinces, the National Assembly, and any joint sessions. The National Assembly is formed by 400 members from the various South African political parties. The National Assembly is elected by the voting population of South Africa. The National Council of Provinces, NCoP, is formed with 90 provincial delegates which translates to 10 delegates for each province. It is thus composed regardless of population distribution. The NCoP is chosen by the provincial governments/legislatures.</p>
<p>The reports are majoritatively held in English, though when a speaker chooses to use another official language, it is transcribed, and no English translation is given. “Hansard is a substantially verbatim report - with repetitions and redundancies omitted and obvious mistakes corrected - of parliamentary proceedings” (see <a class="reference external" href="https://www.parliament.gov.za/hansard?sorts%5Blanguage%5D=-1&amp;amp;page=5&amp;amp;offset=40">Website of the South African parliament</a>). <span id="id27">Kotze and Van Rooy [<a class="reference internal" href="#id75" title="Haidee Kotze and Bertus Van Rooy. Democratisation in the South African parliamentary Hansard? A study of change in modal auxiliaries. Language Sciences, 79:101264, May 2020. URL: https://linkinghub.elsevier.com/retrieve/pii/S0388000119302906 (visited on 2024-10-05), doi:10.1016/j.langsci.2019.101264.">2020</a>]</span> remark that it is and remains unclear what substantially verbatim conotes in the sense of corrections towards an overstandardisation <span id="id28">[<a class="reference internal" href="#id53" title="Liesel Hibbert. Changing language practices in parliament in South Africa. Southern African Linguistics and Applied Language Studies, 21(3):103–117, August 2003. URL: http://www.tandfonline.com/doi/abs/10.2989/16073610309486334 (visited on 2024-11-11), doi:10.2989/16073610309486334.">Hibbert, 2003</a>, <a class="reference internal" href="#id52" title="Liesel Hibbert. The linguistic landscape of post-Apartheid South Africa: politics and discourse. Multilingual Matters, Bristol, 2016. ISBN 978-1-78309-582-7. OCLC: 953565613.">Hibbert, 2016</a>, <a class="reference internal" href="#id75" title="Haidee Kotze and Bertus Van Rooy. Democratisation in the South African parliamentary Hansard? A study of change in modal auxiliaries. Language Sciences, 79:101264, May 2020. URL: https://linkinghub.elsevier.com/retrieve/pii/S0388000119302906 (visited on 2024-10-05), doi:10.1016/j.langsci.2019.101264.">Kotze and Van Rooy, 2020</a>]</span>.<a class="footnote-reference brackets" href="#footnote2" id="id29" role="doc-noteref"><span class="fn-bracket">[</span>2<span class="fn-bracket">]</span></a></p>
<p>The decision was made to process all reports of 2020 from the National Assembly, henceforth abbreviated as NA. The data thus excludes any other years, all joint sittings, all meetings of the NCoP and all mini plenary sessions. The decision to look at the NA was made to maximise the possible speaker count and because it holds the most sessions of all parliamentray chambers. In total 51 sessions were held in 2020.</p>
<section id="parlamint">
<h4>ParlaMint<a class="headerlink" href="#parlamint" title="Link to this heading">#</a></h4>
<p>To ensure that the data in this corpus remains both human- and machine-readable while adhering to widely accepted standards, it was decided to encode the transcriptions in XML using the ParlaMint schema <span id="id30">[<a class="reference internal" href="#id64" title="Tomaž Erjavec, Maciej Ogrodniczuk, and Petya et al. Osenova. The parlamint corpora of parliamentary proceedings. Language Resources &amp; Evaluation, 57:415–448, 2022. URL: https://doi.org/10.1007/s10579-021-09574-0, doi:10.1007/s10579-021-09574-0.">Erjavec <em>et al.</em>, 2022</a>]</span>, a customisation of the Parla-Clarina schema, which itself is based on the Text Encoding Initiative (TEI) guidelines <span id="id31">[<a class="reference internal" href="#id63" title="TEI Consortium. TEI P5: Guidelines for Electronic Text Encoding and Interchange. TEI Consortium, 2024. Version 4.6.0. Accessed: 2024-11-20. URL: https://tei-c.org/release/doc/tei-p5-doc/en/Guidelines.pdf.">TEI Consortium, 2024</a>]</span>. This approach allows the corpus to maintain a consistent structure while also providing a way to encode the specific nuances of parliamentary discourse.</p>
<p>The decision to adopt TEI, and specifically the ParlaMint schema, was guided by several considerations, specifically the goal of adhering to the FAIR principles. TEI’s flexibility allows for the encoding of a diverse range of textual features, including but not limited to metadata about speakers. The ParlaMint schema, as a specialized extension of TEI, was designed standardise the encoding of parliamentary data across various languages and regions <span id="id32">[<a class="reference internal" href="#id60" title="Maciej Ogrodniczuk. Towards Including South African Hansard Papers in the ParlaMint schema. Journal of the Digital Humanities Association of Southern Africa (DHASA), February 2024. URL: https://upjournals.up.ac.za/index.php/dhasa/article/view/5025 (visited on 2024-09-23).">Ogrodniczuk, 2024</a>]</span> and allows for the encoding of a wide variety of metadata while following a strict structure to enable maximal interoperability <span id="id33">[<a class="reference internal" href="#id64" title="Tomaž Erjavec, Maciej Ogrodniczuk, and Petya et al. Osenova. The parlamint corpora of parliamentary proceedings. Language Resources &amp; Evaluation, 57:415–448, 2022. URL: https://doi.org/10.1007/s10579-021-09574-0, doi:10.1007/s10579-021-09574-0.">Erjavec <em>et al.</em>, 2022</a>]</span>. In addition to the strict encoding guidelines for data and metadata provided by the ParlaMint schema, it also allows for meticulous documentation of the process to enable reusability for future research using this data. Overall, the ParlaMint was designed to adhere to the FAIR principles as closely as possible <span id="id34">[<a class="reference internal" href="#id64" title="Tomaž Erjavec, Maciej Ogrodniczuk, and Petya et al. Osenova. The parlamint corpora of parliamentary proceedings. Language Resources &amp; Evaluation, 57:415–448, 2022. URL: https://doi.org/10.1007/s10579-021-09574-0, doi:10.1007/s10579-021-09574-0.">Erjavec <em>et al.</em>, 2022</a>]</span>. The concluded ParlaMint I project entailed the encoding of corpora containing transcriptions of the sessions of 17 European national parliaments, resulting in a collection of half a billion words <span id="id35">[<a class="reference internal" href="#id65" title="Tomaž Erjavec, Matyáš Kopp, and Katja Meden. Tei and git in parlamint: collaborative development of language resources. In Proceedings of the CLARIN Annual Conference 2022. 2022. URL: https://doi.org/10.3384/ecp198005, doi:10.3384/ecp198005.">Erjavec <em>et al.</em>, 2022</a>]</span>.</p>
<p>Adhering to the ParlaMint schema while encoding the South African Hansard papers would allow this corpus to seamlessly integrate with the ParlaMint I project.</p>
</section>
<section id="pre-processing">
<h4>Pre-Processing<a class="headerlink" href="#pre-processing" title="Link to this heading">#</a></h4>
<p>The preprocessing of the transcriptions involved several steps to ensure consistency and compliance with the ParlaMint schema. This included turning the PDF-documents downloaded from the South African parliament’s website <span id="id36">[<a class="reference internal" href="#id66" title="Parliament of South Africa. Hansard papers (2020). https://www.parliament.gov.za/hansard-papers?sorts[date]=-1, 2020. Accessed: 2024-11-20.">Parliament of South Africa, 2020</a>]</span> into text files, which were then used to create the XML files.
The content of these txt-files was barely edited, save for occassional spelling errors within headers and subtitles.</p>
</section>
</section>
<section id="method">
<h3>Method<a class="headerlink" href="#method" title="Link to this heading">#</a></h3>
<p>To adhere to the FAIR principles the decision was made to harness the capabilities of the Llama Large Language Model family, which was and is developped by Meta <span id="id37">[<a class="reference internal" href="#id73" title="Abhimanyu Dubey, Abhinav Jauhri, and Abhinav et al. Pandey. The Llama 3 Herd of Models. 2024. Version Number: 2. URL: https://arxiv.org/abs/2407.21783 (visited on 2024-11-19), doi:10.48550/ARXIV.2407.21783.">Dubey <em>et al.</em>, 2024</a>, <a class="reference internal" href="#id51" title="Hugo Touvron, Thibaut Lavril, and Gautier et al. Izacard. LLaMA: Open and Efficient Foundation Language Models. February 2023. arXiv:2302.13971 [cs]. URL: http://arxiv.org/abs/2302.13971 (visited on 2024-10-01).">Touvron <em>et al.</em>, 2023</a>]</span>. The Llama models are based on a Transformer architercture <span id="id38">[<a class="reference internal" href="#id73" title="Abhimanyu Dubey, Abhinav Jauhri, and Abhinav et al. Pandey. The Llama 3 Herd of Models. 2024. Version Number: 2. URL: https://arxiv.org/abs/2407.21783 (visited on 2024-11-19), doi:10.48550/ARXIV.2407.21783.">Dubey <em>et al.</em>, 2024</a>]</span>. The Llama families “only use[s] publicly available data, making [their] work compatible with open-sourcing” <span id="id39">[<a class="reference internal" href="#id51" title="Hugo Touvron, Thibaut Lavril, and Gautier et al. Izacard. LLaMA: Open and Efficient Foundation Language Models. February 2023. arXiv:2302.13971 [cs]. URL: http://arxiv.org/abs/2302.13971 (visited on 2024-10-01).">Touvron <em>et al.</em>, 2023</a>]</span>. It was thus possible to release the Llama models as open source with some restrictions to access. This chapter uses the newest release of the model family, Llama 3, of which the largest model employs 405 bilion parameters <span id="id40">[<a class="reference internal" href="#id73" title="Abhimanyu Dubey, Abhinav Jauhri, and Abhinav et al. Pandey. The Llama 3 Herd of Models. 2024. Version Number: 2. URL: https://arxiv.org/abs/2407.21783 (visited on 2024-11-19), doi:10.48550/ARXIV.2407.21783.">Dubey <em>et al.</em>, 2024</a>]</span>. However, Llama makes available multiple sets of pretrained models with different quantities of parameters, offering the possibility of maximising minimal parameter count to maximum quality output. The smaller models are “best-in-class, outperforming alternative models with similar numbers of parameters” <span id="id41">[<a class="reference internal" href="#id73" title="Abhimanyu Dubey, Abhinav Jauhri, and Abhinav et al. Pandey. The Llama 3 Herd of Models. 2024. Version Number: 2. URL: https://arxiv.org/abs/2407.21783 (visited on 2024-11-19), doi:10.48550/ARXIV.2407.21783.">Dubey <em>et al.</em>, 2024</a>]</span>. The model family was pretrained on 15T tokens which marks a large increase from Llama 2 with 1.8T tokens <span id="id42">[<a class="reference internal" href="#id73" title="Abhimanyu Dubey, Abhinav Jauhri, and Abhinav et al. Pandey. The Llama 3 Herd of Models. 2024. Version Number: 2. URL: https://arxiv.org/abs/2407.21783 (visited on 2024-11-19), doi:10.48550/ARXIV.2407.21783.">Dubey <em>et al.</em>, 2024</a>]</span>.</p>
<figure class="align-default" id="id83">
<img alt="_images/llama_3.jpg" src="_images/llama_3.jpg" />
<figcaption>
<p><span class="caption-number">Fig. 1 </span><span class="caption-text">Here is the caption for llama 3 <span id="id43">[<a class="reference internal" href="#id73" title="Abhimanyu Dubey, Abhinav Jauhri, and Abhinav et al. Pandey. The Llama 3 Herd of Models. 2024. Version Number: 2. URL: https://arxiv.org/abs/2407.21783 (visited on 2024-11-19), doi:10.48550/ARXIV.2407.21783.">Dubey <em>et al.</em>, 2024</a>]</span></span><a class="headerlink" href="#id83" title="Link to this image">#</a></p>
</figcaption>
</figure>
<p>A further issue in harnessing LLMs for data formatting lies in the costliness of training and running of such models. Whilst there is an effort to optimize models , it is still not possible to train a LLM locally on a standard laptop <span id="id44">[<a class="reference internal" href="#id74" title="Haochen Zhang, Yuyang Dong, and Chuan et al. Xiao. Jellyfish: Instruction-Tuning Local Large Language Models for Data Preprocessing. In Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing, 8754–8782. Association for Computational Linguistics, November 2024.">Zhang <em>et al.</em>, 2024</a>]</span>. However, it is possible to run some pretrained models locally, provided that their parameter count is relatively small, and adapt them to a specific task via few-shot prompting. In this context Llama offers small-scale options with their development of the general models Llama 3.2 1B, 3B and 70B, where especially the 1B and the 3B parameter models are runnable on mobile or edge devices <span id="id45">[<a class="reference internal" href="#id73" title="Abhimanyu Dubey, Abhinav Jauhri, and Abhinav et al. Pandey. The Llama 3 Herd of Models. 2024. Version Number: 2. URL: https://arxiv.org/abs/2407.21783 (visited on 2024-11-19), doi:10.48550/ARXIV.2407.21783.">Dubey <em>et al.</em>, 2024</a>]</span>. As the Jellyfish family by Zhan et al. is also based on Llama but finetuned to data processing, it will also be included in the experiments <span id="id46">[<a class="reference internal" href="#id74" title="Haochen Zhang, Yuyang Dong, and Chuan et al. Xiao. Jellyfish: Instruction-Tuning Local Large Language Models for Data Preprocessing. In Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing, 8754–8782. Association for Computational Linguistics, November 2024.">Zhang <em>et al.</em>, 2024</a>]</span>.</p>
<p><strong>Models Used</strong></p>
<ul class="simple">
<li><p>Llama 3.2 1B</p></li>
<li><p>Llama 3.2 3B</p></li>
<li><p>Llama 3 8B</p></li>
<li><p>Jellyfish</p></li>
</ul>
<section id="experiment-setup">
<h4>Experiment Setup<a class="headerlink" href="#experiment-setup" title="Link to this heading">#</a></h4>
<p>Here we describe the use of the gold-standard xml for training etc.</p>
</section>
</section>
</section>
<section id="experiments-and-results">
<h2>Experiments and Results<a class="headerlink" href="#experiments-and-results" title="Link to this heading">#</a></h2>
<p>In a primary approach, the attempt was made to guide a locally run LLM via prompt engineering with a standard prompting approach but enriched with an example <span id="id47">[<a class="reference internal" href="#id54" title="Humza Naveed, Asad Ullah Khan, and Shi et al. Qiu. A Comprehensive Overview of Large Language Models. 2023. Version Number: 9. doi:10.48550/ARXIV.2307.06435.">Naveed <em>et al.</em>, 2023</a>, <a class="reference internal" href="#id77" title="Aishwarya Vijayan. A Prompt Engineering Approach for Structured Data Extraction from Unstructured Text Using Conversational LLMs. In 2023 6th International Conference on Algorithms, Computing and Artificial Intelligence, 183–189. Sanya China, December 2023. ACM. URL: https://dl.acm.org/doi/10.1145/3639631.3639663 (visited on 2024-11-27), doi:10.1145/3639631.3639663.">Vijayan, 2023</a>]</span>. This decision to utilize a standard prompting appraoch was made to accomodate the context windows of the models tested. To work with the context window given, the files had to be chunked. The decision was made not to enlargen the context windows as larger context windows generally amplify hallucinations, which in the case of dataformatting would be detrimental.</p>
<p>Ollama was chosen as basesoftware as it offers the smaller Llama 3.2 models in a downloadable fashion. Furthermore, Ollama linked to langchain to customise its prompting abilities as Ollama offers limited customization options, though this is subject to swift changes <a class="footnote-reference brackets" href="#footnote" id="id48" role="doc-noteref"><span class="fn-bracket">[</span>3<span class="fn-bracket">]</span></a>. Langchain offers flexibility with regards to customisation <span id="id49">[]</span>.</p>
<p>In the first attempt the model was given a prompt of the structure:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">example_xml</span> <span class="o">=</span> <span class="sa">f</span><span class="s1">&#39;&lt;note type=&quot;speaker&quot;&gt;The CHIEF WHIP OF THE MAJORITY PARTY:&lt;/note&gt;</span>
            <span class="o">&lt;</span><span class="n">u</span> <span class="n">xml</span><span class="p">:</span><span class="nb">id</span><span class="o">=</span><span class="s2">&quot;25-02-2020_u16&quot;</span> <span class="n">who</span><span class="o">=</span><span class="s2">&quot;#ChiefWhipOfMajorityParty&quot;</span><span class="o">&gt;</span> 
                <span class="o">&lt;</span><span class="n">seg</span> <span class="n">xml</span><span class="p">:</span><span class="n">lang</span><span class="o">=</span><span class="s2">&quot;en&quot;</span><span class="o">&gt;</span>
                    <span class="n">Thank</span> <span class="n">you</span> <span class="n">very</span> <span class="n">much</span><span class="p">,</span> <span class="n">House</span> <span class="n">Chair</span><span class="o">.</span> <span class="n">As</span> <span class="n">indicated</span> <span class="n">on</span> <span class="n">the</span> <span class="n">Order</span> <span class="n">Paper</span> <span class="n">we</span> <span class="n">shall</span> <span class="n">proceed</span><span class="o">.</span>
                <span class="o">&lt;/</span><span class="n">seg</span><span class="o">&gt;</span><span class="s1">&#39;</span>
<span class="n">example_txt</span> <span class="o">=</span> <span class="sa">f</span><span class="s1">&#39;The CHIEF WHIP OF THE MAJORITY PARTY: Thank you very much, House Chair. As indicated on the Order Paper we shall proceed.&#39;</span>
<span class="n">question_1</span> <span class="o">=</span> <span class="sa">f</span><span class="s1">&#39;If given raw text: </span><span class="si">{</span><span class="n">example_txt</span><span class="si">}</span><span class="s1"> with the end goal: </span><span class="si">{</span><span class="n">example_xml</span><span class="si">}</span><span class="s1">, can you adapt this: </span><span class="si">{</span><span class="n">chunk</span><span class="si">}</span><span class="s1"> into the same xml format?&#39;</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output traceback highlight-ipythontb notranslate"><div class="highlight"><pre><span></span>  <span class="n">Cell</span> <span class="n">In</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">line</span> <span class="mi">1</span>
    <span class="n">example_xml</span> <span class="o">=</span> <span class="sa">f</span><span class="s1">&#39;&lt;note type=&quot;speaker&quot;&gt;The CHIEF WHIP OF THE MAJORITY PARTY:&lt;/note&gt;</span>
                  <span class="o">^</span>
<span class="ne">SyntaxError</span>: unterminated f-string literal (detected at line 1)
</pre></div>
</div>
</div>
</div>
<p>A code example is given below with Llama 3.2 configured:</p>
<div class="admonition tip">
<p class="admonition-title">Tip</p>
<p>Make sure that you close Ollama before serving it on the command line, otherwise it will not work.</p>
<p>To exit Ollama in the command line press ctrl + c.</p>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">os</span>
<span class="kn">from</span> <span class="nn">langchain_core.prompts</span> <span class="kn">import</span> <span class="n">ChatPromptTemplate</span>
<span class="kn">from</span> <span class="nn">langchain_ollama.llms</span> <span class="kn">import</span> <span class="n">OllamaLLM</span>

<span class="n">folder_path</span> <span class="o">=</span> <span class="sa">r</span><span class="s1">&#39;test_objects&#39;</span>


<span class="n">template</span> <span class="o">=</span> <span class="s2">&quot;&quot;&quot;Question: </span><span class="si">{question}</span>

<span class="s2">Answer: Let&#39;s think step by step.&quot;&quot;&quot;</span>

<span class="n">prompt</span> <span class="o">=</span> <span class="n">ChatPromptTemplate</span><span class="o">.</span><span class="n">from_template</span><span class="p">(</span><span class="n">template</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">OllamaLLM</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="s2">&quot;llama3.2&quot;</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">chunk_text</span><span class="p">(</span><span class="n">text</span><span class="p">,</span> <span class="n">chunk_size</span><span class="o">=</span><span class="mi">5000</span><span class="p">):</span>
    <span class="n">words</span> <span class="o">=</span> <span class="n">text</span><span class="o">.</span><span class="n">split</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">words</span><span class="p">),</span> <span class="n">chunk_size</span><span class="p">):</span>
        <span class="k">yield</span> <span class="s1">&#39; &#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">words</span><span class="p">[</span><span class="n">i</span><span class="p">:</span><span class="n">i</span> <span class="o">+</span> <span class="n">chunk_size</span><span class="p">])</span>

<span class="k">for</span> <span class="n">filename</span> <span class="ow">in</span> <span class="n">os</span><span class="o">.</span><span class="n">listdir</span><span class="p">(</span><span class="n">folder_path</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">filename</span><span class="o">.</span><span class="n">endswith</span><span class="p">(</span><span class="s1">&#39;.txt&#39;</span><span class="p">):</span>
        <span class="n">file_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">folder_path</span><span class="p">,</span> <span class="n">filename</span><span class="p">)</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">file_path</span><span class="p">,</span> <span class="s1">&#39;r&#39;</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s1">&#39;utf-8&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">file</span><span class="p">:</span>
                <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Processing file: </span><span class="si">{</span><span class="n">filename</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
                <span class="n">content</span> <span class="o">=</span> <span class="n">file</span><span class="o">.</span><span class="n">read</span><span class="p">()</span>
                <span class="n">document_list</span> <span class="o">=</span> <span class="p">[]</span>
                <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span>
                <span class="k">for</span> <span class="n">chunk</span> <span class="ow">in</span> <span class="n">chunk_text</span><span class="p">(</span><span class="n">content</span><span class="p">,</span> <span class="n">chunk_size</span><span class="o">=</span><span class="mi">1000</span><span class="p">):</span>
                    <span class="k">try</span><span class="p">:</span>
                        <span class="n">question</span> <span class="o">=</span> <span class="n">question_1</span>
                        <span class="n">response</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">prompt</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">question</span><span class="o">=</span><span class="n">question</span><span class="p">))</span>
                        <span class="n">document_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">response</span><span class="p">)</span>
                        <span class="n">i</span> <span class="o">+=</span> <span class="mi">1</span>
                        <span class="k">if</span> <span class="n">i</span> <span class="o">==</span> <span class="mi">4</span><span class="p">:</span>  <span class="c1"># Limit iterations for testing</span>
                            <span class="k">break</span>
                    <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
                        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Error processing chunk: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
                <span class="n">output_file</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">folder_path</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">splitext</span><span class="p">(</span><span class="n">filename</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="s2">.xml&quot;</span><span class="p">)</span>
                <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">output_file</span><span class="p">,</span> <span class="s1">&#39;w&#39;</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s1">&#39;utf-8&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">output</span><span class="p">:</span>
                    <span class="n">output</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">document_list</span><span class="p">))</span>
        <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Error reading file </span><span class="si">{</span><span class="n">filename</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="results-discussion">
<h2>Results &amp; Discussion<a class="headerlink" href="#results-discussion" title="Link to this heading">#</a></h2>
<section id="limitations">
<h3>Limitations<a class="headerlink" href="#limitations" title="Link to this heading">#</a></h3>
<p>Problems: specific world knowledge that is needed to fill in the metadata, size of context window, computational power/resources.
Prompt Engineering on local llms (Why it doesn’t work for this specific case, why it didn’t work for us.) -&gt; the limited context window paired with the large input, the inability to work with unaltered text, computational issues/hardware issues. Batching didn’t work.</p>
</section>
</section>
<section id="conclusion">
<h2>Conclusion<a class="headerlink" href="#conclusion" title="Link to this heading">#</a></h2>
</section>
<section id="bibliography">
<h2>Bibliography<a class="headerlink" href="#bibliography" title="Link to this heading">#</a></h2>
<div class="docutils container" id="id50">
<div role="list" class="citation-list">
<div class="citation" id="id68" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>1<span class="fn-bracket">]</span></span>
<span class="backrefs">(<a role="doc-backlink" href="#id21">1</a>,<a role="doc-backlink" href="#id22">2</a>,<a role="doc-backlink" href="#id26">3</a>)</span>
<p>Simran Arora, Brandon Yang, and Sabri et al. Eyuboglu. Language Models Enable Simple Systems for Generating Structured Views of Heterogeneous Data Lakes. <em>Proceedings of the VLDB Endowment</em>, 17(2):92–105, October 2023. URL: <a class="reference external" href="https://dl.acm.org/doi/10.14778/3626292.3626294">https://dl.acm.org/doi/10.14778/3626292.3626294</a> (visited on 2024-10-16), <a class="reference external" href="https://doi.org/10.14778/3626292.3626294">doi:10.14778/3626292.3626294</a>.</p>
</div>
<div class="citation" id="id70" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id18">2</a><span class="fn-bracket">]</span></span>
<p>Tim Beck, Tom Shorter, and Yan et al. Hu. Auto-CORPus: A Natural Language Processing Tool for Standardizing and Reusing Biomedical Literature. <em>Frontiers in Digital Health</em>, 4:788124, February 2022. URL: <a class="reference external" href="https://www.frontiersin.org/articles/10.3389/fdgth.2022.788124/full">https://www.frontiersin.org/articles/10.3389/fdgth.2022.788124/full</a> (visited on 2024-10-09), <a class="reference external" href="https://doi.org/10.3389/fdgth.2022.788124">doi:10.3389/fdgth.2022.788124</a>.</p>
</div>
<div class="citation" id="id81" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id4">3</a><span class="fn-bracket">]</span></span>
<p>Lou Burnard. The Evolution of the Text Encoding Initiative: From Research Project to Research Infrastructure. <em>Journal of the Text Encoding Initiative</em>, April 2013. URL: <a class="reference external" href="http://journals.openedition.org/jtei/811">http://journals.openedition.org/jtei/811</a> (visited on 2024-11-28), <a class="reference external" href="https://doi.org/10.4000/jtei.811">doi:10.4000/jtei.811</a>.</p>
</div>
<div class="citation" id="id67" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>4<span class="fn-bracket">]</span></span>
<span class="backrefs">(<a role="doc-backlink" href="#id1">1</a>,<a role="doc-backlink" href="#id21">2</a>,<a role="doc-backlink" href="#id25">3</a>)</span>
<p>Zui Chen, Lei Cao, and Sam et al. Madden. SEED: Domain-Specific Data Curation With Large Language Models. 2023. Version Number: 3. URL: <a class="reference external" href="https://arxiv.org/abs/2310.00749">https://arxiv.org/abs/2310.00749</a> (visited on 2024-10-16), <a class="reference external" href="https://doi.org/10.48550/ARXIV.2310.00749">doi:10.48550/ARXIV.2310.00749</a>.</p>
</div>
<div class="citation" id="id59" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id16">5</a><span class="fn-bracket">]</span></span>
<p>Niall Curry, Paul Baker, and Gavin Brookes. Generative AI for corpus approaches to discourse studies: A critical evaluation of ChatGPT. <em>Applied Corpus Linguistics</em>, 4(1):100082, April 2024. URL: <a class="reference external" href="https://linkinghub.elsevier.com/retrieve/pii/S2666799123000424">https://linkinghub.elsevier.com/retrieve/pii/S2666799123000424</a> (visited on 2024-09-27).</p>
</div>
<div class="citation" id="id73" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>6<span class="fn-bracket">]</span></span>
<span class="backrefs">(<a role="doc-backlink" href="#id37">1</a>,<a role="doc-backlink" href="#id38">2</a>,<a role="doc-backlink" href="#id40">3</a>,<a role="doc-backlink" href="#id41">4</a>,<a role="doc-backlink" href="#id42">5</a>,<a role="doc-backlink" href="#id43">6</a>,<a role="doc-backlink" href="#id45">7</a>)</span>
<p>Abhimanyu Dubey, Abhinav Jauhri, and Abhinav et al. Pandey. The Llama 3 Herd of Models. 2024. Version Number: 2. URL: <a class="reference external" href="https://arxiv.org/abs/2407.21783">https://arxiv.org/abs/2407.21783</a> (visited on 2024-11-19), <a class="reference external" href="https://doi.org/10.48550/ARXIV.2407.21783">doi:10.48550/ARXIV.2407.21783</a>.</p>
</div>
<div class="citation" id="id65" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id35">7</a><span class="fn-bracket">]</span></span>
<p>Tomaž Erjavec, Matyáš Kopp, and Katja Meden. Tei and git in parlamint: collaborative development of language resources. In <em>Proceedings of the CLARIN Annual Conference 2022</em>. 2022. URL: <a class="reference external" href="https://doi.org/10.3384/ecp198005">https://doi.org/10.3384/ecp198005</a>, <a class="reference external" href="https://doi.org/10.3384/ecp198005">doi:10.3384/ecp198005</a>.</p>
</div>
<div class="citation" id="id80" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>8<span class="fn-bracket">]</span></span>
<span class="backrefs">(<a role="doc-backlink" href="#id8">1</a>,<a role="doc-backlink" href="#id10">2</a>)</span>
<p>Tomaž Erjavec, Maciej Ogrodniczuk, Petya Osenova, Nikola Ljubešić, Kiril Simov, Andrej Pančur, Michał Rudolf, Matyáš Kopp, Starkaður Barkarson, Steinþór Steingrímsson, Çağrı Çöltekin, Jesse De Does, Katrien Depuydt, Tommaso Agnoloni, Giulia Venturi, María Calzada Pérez, Luciana D. De Macedo, Costanza Navarretta, Giancarlo Luxardo, Matthew Coole, Paul Rayson, Vaidas Morkevičius, Tomas Krilavičius, Roberts Darǵis, Orsolya Ring, Ruben Van Heusden, Maarten Marx, and Darja Fišer. The ParlaMint corpora of parliamentary proceedings. <em>Language Resources and Evaluation</em>, 57(1):415–448, March 2023. URL: <a class="reference external" href="https://link.springer.com/10.1007/s10579-021-09574-0">https://link.springer.com/10.1007/s10579-021-09574-0</a> (visited on 2024-10-01), <a class="reference external" href="https://doi.org/10.1007/s10579-021-09574-0">doi:10.1007/s10579-021-09574-0</a>.</p>
</div>
<div class="citation" id="id64" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>9<span class="fn-bracket">]</span></span>
<span class="backrefs">(<a role="doc-backlink" href="#id30">1</a>,<a role="doc-backlink" href="#id33">2</a>,<a role="doc-backlink" href="#id34">3</a>)</span>
<p>Tomaž Erjavec, Maciej Ogrodniczuk, and Petya et al. Osenova. The parlamint corpora of parliamentary proceedings. <em>Language Resources &amp; Evaluation</em>, 57:415–448, 2022. URL: <a class="reference external" href="https://doi.org/10.1007/s10579-021-09574-0">https://doi.org/10.1007/s10579-021-09574-0</a>, <a class="reference external" href="https://doi.org/10.1007/s10579-021-09574-0">doi:10.1007/s10579-021-09574-0</a>.</p>
</div>
<div class="citation" id="id79" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id7">10</a><span class="fn-bracket">]</span></span>
<p><strong>missing journal in erjavec_2019</strong></p>
</div>
<div class="citation" id="id53" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>11<span class="fn-bracket">]</span></span>
<span class="backrefs">(<a role="doc-backlink" href="#id28">1</a>,<a role="doc-backlink" href="#id82">2</a>)</span>
<p>Liesel Hibbert. Changing language practices in parliament in South Africa. <em>Southern African Linguistics and Applied Language Studies</em>, 21(3):103–117, August 2003. URL: <a class="reference external" href="http://www.tandfonline.com/doi/abs/10.2989/16073610309486334">http://www.tandfonline.com/doi/abs/10.2989/16073610309486334</a> (visited on 2024-11-11), <a class="reference external" href="https://doi.org/10.2989/16073610309486334">doi:10.2989/16073610309486334</a>.</p>
</div>
<div class="citation" id="id52" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>12<span class="fn-bracket">]</span></span>
<span class="backrefs">(<a role="doc-backlink" href="#id28">1</a>,<a role="doc-backlink" href="#id82">2</a>)</span>
<p>Liesel Hibbert. <em>The linguistic landscape of post-Apartheid South Africa: politics and discourse</em>. Multilingual Matters, Bristol, 2016. ISBN 978-1-78309-582-7. OCLC: 953565613.</p>
</div>
<div class="citation" id="id61" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id3">13</a><span class="fn-bracket">]</span></span>
<p>Nancy Ide, Laurent Romary, and Eric de la Clergerie. International standard for a linguistic annotation framework. In <em>Proceedings of the HLT-NAACL 2003 Workshop on Software Engineering and Architecture of Language Technology Systems - Volume 8</em>, SEALTS '03, 25––30. USA, 2003. Association for Computational Linguistics. URL: <a class="reference external" href="https://doi.org/10.3115/1119226.1119230">https://doi.org/10.3115/1119226.1119230</a>, <a class="reference external" href="https://doi.org/10.3115/1119226.1119230">doi:10.3115/1119226.1119230</a>.</p>
</div>
<div class="citation" id="id58" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id5">14</a><span class="fn-bracket">]</span></span>
<p>Chris Jeffery. On compiling a corpus of South African English. <em>Southern African Linguistics and Applied Language Studies</em>, 21(4):341–344, November 2003. URL: <a class="reference external" href="http://www.tandfonline.com/doi/abs/10.2989/16073610309486353">http://www.tandfonline.com/doi/abs/10.2989/16073610309486353</a> (visited on 2024-10-05), <a class="reference external" href="https://doi.org/10.2989/16073610309486353">doi:10.2989/16073610309486353</a>.</p>
</div>
<div class="citation" id="id75" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>15<span class="fn-bracket">]</span></span>
<span class="backrefs">(<a role="doc-backlink" href="#id27">1</a>,<a role="doc-backlink" href="#id28">2</a>)</span>
<p>Haidee Kotze and Bertus Van Rooy. Democratisation in the South African parliamentary Hansard? A study of change in modal auxiliaries. <em>Language Sciences</em>, 79:101264, May 2020. URL: <a class="reference external" href="https://linkinghub.elsevier.com/retrieve/pii/S0388000119302906">https://linkinghub.elsevier.com/retrieve/pii/S0388000119302906</a> (visited on 2024-10-05), <a class="reference external" href="https://doi.org/10.1016/j.langsci.2019.101264">doi:10.1016/j.langsci.2019.101264</a>.</p>
</div>
<div class="citation" id="id55" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id3">16</a><span class="fn-bracket">]</span></span>
<p>Alexander König, Jennifer-Carmen Frey, and Egon W. Stemle. Exploring Reusability and Reproducibility for a Research Infrastructure for L1 and L2 Learner Corpora. <em>Information</em>, 12(5):199, April 2021. URL: <a class="reference external" href="https://www.mdpi.com/2078-2489/12/5/199">https://www.mdpi.com/2078-2489/12/5/199</a> (visited on 2024-10-30), <a class="reference external" href="https://doi.org/10.3390/info12050199">doi:10.3390/info12050199</a>.</p>
</div>
<div class="citation" id="id71" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id17">17</a><span class="fn-bracket">]</span></span>
<p>Louis Létinier, Julien Jouganous, and Mehdi et al. Benkebil. Artificial Intelligence for Unstructured Healthcare Data: Application to Coding of Patient Reporting of Adverse Drug Reactions. <em>Clinical Pharmacology &amp; Therapeutics</em>, 110(2):392–400, August 2021. URL: <a class="reference external" href="https://ascpt.onlinelibrary.wiley.com/doi/10.1002/cpt.2266">https://ascpt.onlinelibrary.wiley.com/doi/10.1002/cpt.2266</a> (visited on 2024-10-04), <a class="reference external" href="https://doi.org/10.1002/cpt.2266">doi:10.1002/cpt.2266</a>.</p>
</div>
<div class="citation" id="id69" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id13">18</a><span class="fn-bracket">]</span></span>
<p>Avanika Narayan, Ines Chami, Laurel Orr, and Christopher Ré. Can Foundation Models Wrangle Your Data? <em>Proceedings of the VLDB Endowment</em>, 16(4):738–746, December 2022. URL: <a class="reference external" href="https://dl.acm.org/doi/10.14778/3574245.3574258">https://dl.acm.org/doi/10.14778/3574245.3574258</a> (visited on 2024-10-16), <a class="reference external" href="https://doi.org/10.14778/3574245.3574258">doi:10.14778/3574245.3574258</a>.</p>
</div>
<div class="citation" id="id54" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id47">19</a><span class="fn-bracket">]</span></span>
<p>Humza Naveed, Asad Ullah Khan, and Shi et al. Qiu. A Comprehensive Overview of Large Language Models. 2023. Version Number: 9. <a class="reference external" href="https://doi.org/10.48550/ARXIV.2307.06435">doi:10.48550/ARXIV.2307.06435</a>.</p>
</div>
<div class="citation" id="id60" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>20<span class="fn-bracket">]</span></span>
<span class="backrefs">(<a role="doc-backlink" href="#id6">1</a>,<a role="doc-backlink" href="#id9">2</a>,<a role="doc-backlink" href="#id11">3</a>,<a role="doc-backlink" href="#id12">4</a>,<a role="doc-backlink" href="#id32">5</a>)</span>
<p>Maciej Ogrodniczuk. Towards Including South African Hansard Papers in the ParlaMint schema. <em>Journal of the Digital Humanities Association of Southern Africa (DHASA)</em>, February 2024. URL: <a class="reference external" href="https://upjournals.up.ac.za/index.php/dhasa/article/view/5025">https://upjournals.up.ac.za/index.php/dhasa/article/view/5025</a> (visited on 2024-09-23).</p>
</div>
<div class="citation" id="id56" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id5">21</a><span class="fn-bracket">]</span></span>
<p>Leela Pienaar and Vivian De Klerk. Towards a Corpus of South African English: Corralling the Sub-varieties. <em>Lexikos</em>, October 2011. URL: <a class="reference external" href="http://lexikos.journals.ac.za/pub/article/view/444">http://lexikos.journals.ac.za/pub/article/view/444</a> (visited on 2024-10-05), <a class="reference external" href="https://doi.org/10.5788/19-0-444">doi:10.5788/19-0-444</a>.</p>
</div>
<div class="citation" id="id72" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id20">22</a><span class="fn-bracket">]</span></span>
<p>Jaseem Pookandy. AI-Based Data Cleaning and Management in Salesforce CRM for Improving Data Integrity and Accuracy to Enhance Customer Insights. <em>International Journal of Advanced Research in Engineering and Technology</em>, 13(5):108–116, May 2022. URL: <a class="reference external" href="https://iaeme.com/Home/issue/IJARET?Volume=13&amp;Issue=5">https://iaeme.com/Home/issue/IJARET?Volume=13&amp;Issue=5</a>.</p>
</div>
<div class="citation" id="id51" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>23<span class="fn-bracket">]</span></span>
<span class="backrefs">(<a role="doc-backlink" href="#id37">1</a>,<a role="doc-backlink" href="#id39">2</a>)</span>
<p>Hugo Touvron, Thibaut Lavril, and Gautier et al. Izacard. LLaMA: Open and Efficient Foundation Language Models. February 2023. arXiv:2302.13971 [cs]. URL: <a class="reference external" href="http://arxiv.org/abs/2302.13971">http://arxiv.org/abs/2302.13971</a> (visited on 2024-10-01).</p>
</div>
<div class="citation" id="id78" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id12">24</a><span class="fn-bracket">]</span></span>
<p>Naomi Truan and Laurent Romary. Building, Encoding, and Annotating a Corpus of Parliamentary Debates in TEI XML: A Cross-Linguistic Account. <em>Journal of the Text Encoding Initiative</em>, March 2021. URL: <a class="reference external" href="http://journals.openedition.org/jtei/4164">http://journals.openedition.org/jtei/4164</a> (visited on 2024-09-27), <a class="reference external" href="https://doi.org/10.4000/jtei.4164">doi:10.4000/jtei.4164</a>.</p>
</div>
<div class="citation" id="id77" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id47">25</a><span class="fn-bracket">]</span></span>
<p>Aishwarya Vijayan. A Prompt Engineering Approach for Structured Data Extraction from Unstructured Text Using Conversational LLMs. In <em>2023 6th International Conference on Algorithms, Computing and Artificial Intelligence</em>, 183–189. Sanya China, December 2023. ACM. URL: <a class="reference external" href="https://dl.acm.org/doi/10.1145/3639631.3639663">https://dl.acm.org/doi/10.1145/3639631.3639663</a> (visited on 2024-11-27), <a class="reference external" href="https://doi.org/10.1145/3639631.3639663">doi:10.1145/3639631.3639663</a>.</p>
</div>
<div class="citation" id="id62" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id2">26</a><span class="fn-bracket">]</span></span>
<p>Mark D. Wilkinson, Michel Dumontier, and IJsbrand Jan Aalbersberg. The FAIR Guiding Principles for scientific data management and stewardship. <em>Scientific Data</em>, 3:1–9, March 2016. URL: <a class="reference external" href="https://doi.org/10.1038/sdata.2016.18">https://doi.org/10.1038/sdata.2016.18</a>, <a class="reference external" href="https://doi.org/10.1038/sdata.2016.18">doi:10.1038/sdata.2016.18</a>.</p>
</div>
<div class="citation" id="id57" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id15">27</a><span class="fn-bracket">]</span></span>
<p>Michele Zappavigna. Hack your corpus analysis: How AI can assist corpus linguists deal with messy social media data. <em>Applied Corpus Linguistics</em>, 3(3):100067, December 2023. URL: <a class="reference external" href="https://linkinghub.elsevier.com/retrieve/pii/S2666799123000278">https://linkinghub.elsevier.com/retrieve/pii/S2666799123000278</a> (visited on 2024-10-01), <a class="reference external" href="https://doi.org/10.1016/j.acorp.2023.100067">doi:10.1016/j.acorp.2023.100067</a>.</p>
</div>
<div class="citation" id="id74" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>28<span class="fn-bracket">]</span></span>
<span class="backrefs">(<a role="doc-backlink" href="#id13">1</a>,<a role="doc-backlink" href="#id14">2</a>,<a role="doc-backlink" href="#id24">3</a>,<a role="doc-backlink" href="#id44">4</a>,<a role="doc-backlink" href="#id46">5</a>)</span>
<p>Haochen Zhang, Yuyang Dong, and Chuan et al. Xiao. Jellyfish: Instruction-Tuning Local Large Language Models for Data Preprocessing. In <em>Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing</em>, 8754–8782. Association for Computational Linguistics, November 2024.</p>
</div>
<div class="citation" id="id66" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id36">29</a><span class="fn-bracket">]</span></span>
<p>Parliament of South Africa. Hansard papers (2020). <a class="reference external" href="https://www.parliament.gov.za/hansard-papers?sorts[date]=-1">https://www.parliament.gov.za/hansard-papers?sorts[date]=-1</a>, 2020. Accessed: 2024-11-20.</p>
</div>
<div class="citation" id="id63" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id31">30</a><span class="fn-bracket">]</span></span>
<p>TEI Consortium. <em>TEI P5: Guidelines for Electronic Text Encoding and Interchange</em>. TEI Consortium, 2024. Version 4.6.0. Accessed: 2024-11-20. URL: <a class="reference external" href="https://tei-c.org/release/doc/tei-p5-doc/en/Guidelines.pdf">https://tei-c.org/release/doc/tei-p5-doc/en/Guidelines.pdf</a>.</p>
</div>
</div>
</div>
<hr class="footnotes docutils" />
<aside class="footnote-list brackets">
<aside class="footnote brackets" id="footnote1" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id23">1</a><span class="fn-bracket">]</span></span>
<p>SEED is currently undergoing restructuring and thus cannot be used. It seems to be a promising project for further investigation into processing raw data via LLM, see <a class="reference external" href="https://anonymous.4open.science/r/SEED/paper.pdf">SEED repository</a>.</p>
</aside>
<aside class="footnote brackets" id="footnote2" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id29">2</a><span class="fn-bracket">]</span></span>
<p>For a more detailed discussion of editing practices in the South African Hansard view <span id="id82">[<a class="reference internal" href="#id53" title="Liesel Hibbert. Changing language practices in parliament in South Africa. Southern African Linguistics and Applied Language Studies, 21(3):103–117, August 2003. URL: http://www.tandfonline.com/doi/abs/10.2989/16073610309486334 (visited on 2024-11-11), doi:10.2989/16073610309486334.">Hibbert, 2003</a>, <a class="reference internal" href="#id52" title="Liesel Hibbert. The linguistic landscape of post-Apartheid South Africa: politics and discourse. Multilingual Matters, Bristol, 2016. ISBN 978-1-78309-582-7. OCLC: 953565613.">Hibbert, 2016</a>]</span>.</p>
</aside>
<aside class="footnote brackets" id="footnote" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id48">3</a><span class="fn-bracket">]</span></span>
<p>For the newest updates and developments concerning Ollama consult their <a class="reference external" href="https://ollama.com/blog">blog</a>.</p>
</aside>
</aside>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "executablebooks/jupyter-book",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
</div>
                </footer>
              
            </div>
            
            
              
                <dialog id="pst-secondary-sidebar-modal"></dialog>
                <div id="pst-secondary-sidebar" class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#abstract">Abstract</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#introduction">Introduction</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#relevant-literature">Relevant Literature</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#data-and-methods">Data and Methods</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#data">Data</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#parlamint">ParlaMint</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#pre-processing">Pre-Processing</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#method">Method</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#experiment-setup">Experiment Setup</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#experiments-and-results">Experiments and Results</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#results-discussion">Results &amp; Discussion</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#limitations">Limitations</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#conclusion">Conclusion</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#bibliography">Bibliography</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Phillip B. Ströbel
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2023.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script defer src="_static/scripts/bootstrap.js?digest=26a4bc78f4c0ddb94549"></script>
<script defer src="_static/scripts/pydata-sphinx-theme.js?digest=26a4bc78f4c0ddb94549"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>